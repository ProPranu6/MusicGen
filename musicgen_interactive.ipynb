{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypianoroll as ppr \n",
    "import numpy as np\n",
    "import os\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Flatten, Input, Bidirectional, TimeDistributed, Activation, Concatenate, Embedding, MaxPooling1D, CategoryEncoding, Conv1D, Dropout\n",
    "from tensorflow.keras.utils import pad_sequences, timeseries_dataset_from_array, split_dataset, to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import calendar\n",
    "import time\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTRUMENTS = 1\n",
    "PITCHES = 129\n",
    "\n",
    "def resample(empties_boolean, prune_percent=0.7):\n",
    "    resampled_inclusion_beats = [ ]\n",
    "    \n",
    "    for isempty in empties_boolean:\n",
    "        include = True\n",
    "        if isempty :\n",
    "            if random() < prune_percent:  #70% pruning of empty beats\n",
    "                include = False\n",
    "    \n",
    "        resampled_inclusion_beats += [include]\n",
    "\n",
    "    return resampled_inclusion_beats\n",
    "\n",
    "\n",
    "def store_dataset_as_batches(dataset, dataset_name, dataset_type='train'):\n",
    "\n",
    "    for batch_id, batch in enumerate(dataset):\n",
    "        inputs, outputs = batch \n",
    "        try:\n",
    "            np.save(f'lpd_5_batched/{dataset_type}_inputs/{dataset_name}_{batch_id}.npy', inputs)\n",
    "            np.save(f'lpd_5_batched/{dataset_type}_outputs/{dataset_name}_{batch_id}.npy', outputs)\n",
    "        except Exception as E:\n",
    "            print(E)\n",
    "\n",
    "def make_dataset(dir, samples, chunkid, trackid, resolution, batch_size, prune_rest_note_percent, encoder_decoder, input_sequence_len, output_sequence_len):\n",
    "    \n",
    "    track = ppr.load(os.path.join(dir, samples[chunkid+trackid])).binarize().set_resolution(resolution).stack()\n",
    "            \n",
    "    if INSTRUMENTS == 1:\n",
    "        track = track[1:2] # take only guitar for one instrument\n",
    "\n",
    "\n",
    "    # Move axis of tracks\n",
    "    track = np.moveaxis(track, (0, 1, 2), (1, 0, 2)) #(time_steps, 5, 128)\n",
    "\n",
    "    # Concatenate extra dimension at 0 for empty   \n",
    "    track = np.concatenate([np.zeros(track.shape[:-1] + (1,)), track], axis=-1)\n",
    "    track[np.any(track, axis=-1)==False, 0] = 1 \n",
    "\n",
    "\n",
    "    # Argmax results, one pitch at a time step for an instrument, ignores chords\n",
    "    track = track.argmax(axis=-1)\n",
    "\n",
    "    #print(\"Shape before resampling : \", d.shape)\n",
    "    \n",
    "    # Resample from empty beats\n",
    "    empty_beats = (np.sum(track, axis=1) == 0)\n",
    "    inclusion_beats = resample(empty_beats, prune_percent=prune_rest_note_percent)\n",
    "    \n",
    "    track= track[inclusion_beats]\n",
    "\n",
    "    #print(\"Shape after resampling : \", d.shape)\n",
    "    \n",
    "    try:\n",
    "        if encoder_decoder:\n",
    "            input_track = track[:-output_sequence_len]\n",
    "            output_track = track[input_sequence_len:]\n",
    "        else:\n",
    "            input_track = track[:-1]\n",
    "            output_track = track[1:]\n",
    "        \n",
    "\n",
    "        input_dataset = timeseries_dataset_from_array(input_track, None, sequence_length=input_sequence_len, sequence_stride=1, batch_size=batch_size)\n",
    "        output_dataset = timeseries_dataset_from_array(output_track, None, sequence_length=input_sequence_len, sequence_stride=1, batch_size=batch_size)\n",
    "        dataset_len = len(input_dataset)\n",
    "    \n",
    "        dataset = zip(input_dataset, output_dataset)\n",
    "        #else:\n",
    "        #    dataset = timeseries_dataset_from_array(track, track[input_sequence_len:], sequence_length=input_sequence_len, sequence_stride=1, batch_size=batch_size)\n",
    "        #    dataset_len = len(dataset)\n",
    "            \n",
    "    except Exception as E:\n",
    "        dataset = None\n",
    "        pass\n",
    "    \n",
    "    return dataset \n",
    "\n",
    "def process_dataset_in_chunks(dir, input_sequence_len=2400, output_sequence_len=None, batch_size=64, topn=-1, train_size=0.8, val_size=0.2, resolution=24, prune_rest_note_percent=0.3, encoder_decoder=False):\n",
    "    samples = os.listdir(dir)[:topn]\n",
    "    train_samples, test_samples = train_test_split(samples, train_size=train_size, shuffle=True)\n",
    "    train_samples, val_samples = train_test_split(train_samples, test_size=val_size, shuffle=False)\n",
    "\n",
    "    chunk_size = len(train_samples)//100 #100th of total sample count\n",
    "    chunk_size = chunk_size if chunk_size else 1\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree('lpd_5_batched/train_inputs')\n",
    "        shutil.rmtree('lpd_5_batched/train_outputs')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree('lpd_5_batched/val_inputs')\n",
    "        shutil.rmtree('lpd_5_batched/val_outputs')\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree('lpd_5_batched/test_inputs')\n",
    "        shutil.rmtree('lpd_5_batched/test_outputs')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    os.makedirs(f'lpd_5_batched/train_inputs')\n",
    "    os.makedirs(f'lpd_5_batched/train_outputs')\n",
    "\n",
    "    os.makedirs(f'lpd_5_batched/val_inputs')\n",
    "    os.makedirs(f'lpd_5_batched/val_outputs')\n",
    "\n",
    "    os.makedirs(f'lpd_5_batched/test_inputs')\n",
    "    os.makedirs(f'lpd_5_batched/test_outputs')\n",
    "\n",
    "\n",
    "    #gmt = time.gmtime()\n",
    "    #ts = calendar.timegm(gmt)\n",
    "    for chunkid in tqdm(range(0, len(train_samples),chunk_size),desc='Preparing Training Dataset...'):\n",
    "        for trackid in range(chunk_size):\n",
    "            dataset = make_dataset(dir, train_samples, chunkid, trackid, resolution, batch_size, prune_rest_note_percent, encoder_decoder, input_sequence_len, output_sequence_len)\n",
    "            if dataset:\n",
    "                store_dataset_as_batches(dataset, dataset_name=f'Pr{os.path.basename(dir)}-Ch{chunkid}-Tr{trackid}', dataset_type='train')\n",
    "    \n",
    "    chunk_size = len(val_samples)//100 #100th of total sample count\n",
    "    chunk_size = chunk_size if chunk_size else 1\n",
    "\n",
    "    for chunkid in tqdm(range(0, len(val_samples),chunk_size),desc='Preparing Validation Dataset...'):\n",
    "        for trackid in range(chunk_size):\n",
    "            dataset = make_dataset(dir, val_samples, chunkid, trackid, resolution, batch_size, prune_rest_note_percent, encoder_decoder, input_sequence_len, output_sequence_len)\n",
    "            if dataset:\n",
    "                store_dataset_as_batches(dataset, dataset_name=f'Pr{os.path.basename(dir)}-Ch{chunkid}-Tr{trackid}', dataset_type='val')\n",
    "            \n",
    "            \n",
    "\n",
    "    for trackid in tqdm(range(0, len(test_samples), 1), desc='Preparing Test Dataset...'):\n",
    "        track = ppr.load(os.path.join(dir, test_samples[trackid])).binarize().set_resolution(resolution).stack()\n",
    "            \n",
    "        if INSTRUMENTS == 1:\n",
    "            track = track[1:2] # take only guitar for one instrument\n",
    "\n",
    "\n",
    "        # Move axis of tracks\n",
    "        track = np.moveaxis(track, (0, 1, 2), (1, 0, 2)) #(time_setps, 5, 128)\n",
    "\n",
    "        input_track = track[:input_sequence_len]\n",
    "        output_track = track[input_sequence_len:]\n",
    "\n",
    "        try:\n",
    "            np.save(f'lpd_5_batched/test_inputs/Pr{os.path.basename(dir)}-Tr{trackid}.npy', input_track)\n",
    "            np.save(f'lpd_5_batched/test_outputs/Pr{os.path.basename(dir)}-Tr{trackid}.npy', output_track)\n",
    "        except Exception as E:\n",
    "            continue\n",
    "\n",
    "\n",
    "       \n",
    "    \n",
    "    return ('lpd_5_batched/train_inputs/', 'lpd_5_batched/train_outputs/'), ('lpd_5_batched/val_inputs/', 'lpd_5_batched/val_outputs/'),  ('lpd_5_batched/test_inputs/', 'lpd_5_batched/test_outputs/')\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "format_targets = lambda y: tf.unstack(tf.experimental.numpy.moveaxis(y, (0, 1, 2), (1, 2, 0)))[0] if INSTRUMENTS == 1 else tuple(tf.unstack(tf.experimental.numpy.moveaxis(y, (0, 1, 2), (1, 2, 0))))\n",
    "\n",
    "def load_music_batches(input_dir, output_dir, encoder_decoder=True):\n",
    "\n",
    "    while 1:\n",
    "        for inp_batch, output_batch in zip(os.listdir(input_dir), os.listdir(output_dir)):\n",
    "            \n",
    "            try:\n",
    "                inputs, targets = np.load(os.path.join(input_dir, inp_batch)), np.load(os.path.join(output_dir, output_batch))\n",
    "                \n",
    "                if encoder_decoder:\n",
    "                    prompt_inputs = np.concatenate([inputs[:, -2:-1], targets[:, :-1]], axis=1)#none, 2400, 5\n",
    "                    yield [inputs, prompt_inputs], format_targets(targets)\n",
    "                else:\n",
    "                    yield inputs, format_targets(targets)\n",
    "            except Exception as E:\n",
    "                continue\n",
    "\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def midi_to_wav(midi_path, output_wav_path):\n",
    "    try:\n",
    "        # Run Timidity++ command to convert MIDI to WAV\n",
    "        subprocess.run([\"timidity\", midi_path, \"-Ow\", \"-o\", output_wav_path], check=True)\n",
    "        print(\"Conversion completed successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Conversion failed.\")\n",
    "\n",
    "\n",
    "def multitrack_to_midi(multitrack, output_path):\n",
    "    # Check and convert tracks if necessary\n",
    "    for i, track in enumerate(multitrack.tracks):\n",
    "        if not isinstance(track, (ppr.BinaryTrack, ppr.StandardTrack)):\n",
    "            print(f\"Converting track {i} to StandardTrack...\")\n",
    "            multitrack.tracks[i] = track.to_pianoroll().to_track()\n",
    "\n",
    "    # Write the multitrack to a MIDI file\n",
    "    multitrack.write(output_path)\n",
    "\n",
    "from random import random, randint\n",
    "\n",
    "\n",
    "def top_p_sampling(probabilities, p):\n",
    "    sorted_indices = np.argsort(probabilities)[::-1]  # Sort probabilities in descending order\n",
    "    cumulative_probs = np.cumsum(probabilities[sorted_indices])  # Compute cumulative probabilities\n",
    "    if np.any(cumulative_probs <= p):\n",
    "        selected_indices = sorted_indices[cumulative_probs <= p]  # Select indices where cumulative probability <= p\n",
    "    else:\n",
    "        # If none of the cumulative probabilities exceed p, select the maximum probability\n",
    "        selected_indices = np.array([np.argmax(probabilities)])\n",
    "    return selected_indices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compose_music(music_model, cue=None, source_loader = None, topn=6, print_gen=False, encoder_decoder=False):  #cue-shape : (cue_len, 5)\n",
    "    \n",
    "\n",
    "    if type(cue) != type(None):\n",
    "        cue = np.concatenate([np.zeros(cue.shape[:-1] + (1,)), cue], axis=-1)\n",
    "        cue[np.any(cue, axis=-1)==False, 0] = 1 \n",
    "        # Argmax results, one pitch at a time step for an instrument, ignores chords\n",
    "        cue = np.expand_dims(cue.argmax(axis=-1), axis=0) #(800, 5)\n",
    "    else:\n",
    "        until = randint(0, 100)\n",
    "        for _ in range(until):\n",
    "            batch = next(source_loader)\n",
    "        \n",
    "        if encoder_decoder:\n",
    "            x = batch[0][0]\n",
    "        else:\n",
    "            x = batch[0]\n",
    "        \n",
    "        cue = np.expand_dims(x[0], axis=0)\n",
    "\n",
    "\n",
    "    composition = [cue[:, -1]]      #List[(1, 5,)]\n",
    "    gen = 1\n",
    "\n",
    "    while True:\n",
    " \n",
    "        if print_gen:\n",
    "            print(\"Generation : \", gen)\n",
    "        gen += 1\n",
    "        pcomp = np.expand_dims(np.concatenate(composition),axis=0)\n",
    "\n",
    "        if encoder_decoder:\n",
    "            pred = np.concatenate(music_model( [cue, pcomp] ))  #(5, 1, 129)\n",
    "        else:\n",
    "            pred = np.concatenate(music_model(pcomp))  #(5, 1, 129)\n",
    "\n",
    "        if INSTRUMENTS == 1:\n",
    "            pred = np.expand_dims(pred, axis=0)\n",
    "\n",
    "\n",
    "  \n",
    "        \n",
    "        preds = []\n",
    "        for instrument in range(INSTRUMENTS):\n",
    "            probs = pred[instrument, -1]\n",
    "            #selected_indices = top_p_sampling(probs, top_p)\n",
    "            #new_probs = np.zeros(probs.shape)\n",
    "            #new_probs[selected_indices] = probs[selected_indices]\n",
    "        \n",
    "            exclude_pred = np.argsort(probs)[:-topn]\n",
    "            #print(np.sort(probs))\n",
    "            probs[exclude_pred] = 0.\n",
    "            #print(probs)\n",
    "            new_probs = probs\n",
    "            new_probs = new_probs/np.sum(new_probs)\n",
    "            \n",
    "            preds += [np.random.choice(129, (1,), p=new_probs)]\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        currcomp = preds.T #(1, 5)\n",
    "        composition += [currcomp]\n",
    "    \n",
    "        yield np.concatenate(composition)\n",
    "    \n",
    "\n",
    "def get_avg_tempo(dir='lpd_5/lpd_5_full/0', topn=1000):\n",
    "    samples = os.listdir(dir)[:topn]\n",
    "    tempo = 0.\n",
    "    count = 0\n",
    "    for sample in samples:\n",
    "        with np.load(os.path.join(dir, sample)) as data:\n",
    "            tempo += np.sum(data['tempo'])\n",
    "            count += data['tempo'].shape[0]\n",
    "    return tempo/count\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_track(composition, tempo=120, from_model=True):\n",
    "\n",
    "\n",
    "    tracks = []\n",
    "    tempo = np.full(composition.shape[0], tempo)  #get the tempo\n",
    "\n",
    "    \n",
    "    track_data = {0 : ['Drums', 0], 1: ['Piano', 0], 2: ['Guitar', 24], 3:['Bass', 32], 4:['Strings', 48]} #{\"is_drum\": false, \"program\": 0, \"name\": \"Piano\"}, \"0\": {\"is_drum\": true, \"program\": 0, \"name\": \"Drums\"}, \"3\": {\"is_drum\": false, \"program\": 32, \"name\": \"Bass\"}, \"2\": {\"is_drum\": false, \"program\": 24, \"name\": \"Guitar\"}, \"4\": {\"is_drum\": false, \"program\": 48, \"name\": \"Strings\"}, \"beat_resolution\": 24}'\n",
    "    if INSTRUMENTS == 1:\n",
    "        track_data = {0:track_data[1]}\n",
    "        \n",
    "    track_names = [t[0] for t in track_data.values()]\n",
    "\n",
    "    # Create a Track object for each track in the multitrack representation\n",
    "    for i, track_name_program in track_data.items():\n",
    "        \n",
    "        track_name, program = track_name_program\n",
    "\n",
    "        if from_model:\n",
    "            piano_roll = CategoryEncoding(129, output_mode='one_hot')(composition[:, i]).numpy()[:, 1:]\n",
    "        else:\n",
    "            piano_roll = composition[:, i]\n",
    "        \n",
    "        # Create a Track object without providing the piano_roll argument\n",
    "        track = ppr.BinaryTrack(name=track_name)\n",
    "        \n",
    "        # Assign piano roll data to the Track object\n",
    "        track.pianoroll = piano_roll  # Assuming piano_roll is a single-track piano roll\n",
    "        track.program = program  # Specify the program number if necessary\n",
    "        \n",
    "        if track_name == 'Drums':\n",
    "            track.is_drum = True\n",
    "        # Append the Track object to the list\n",
    "        tracks.append(track)\n",
    "\n",
    "    # Create a Multitrack object and assign the tracks to it\n",
    "    multitrack = ppr.Multitrack(tracks=tracks, tempo=tempo, resolution=8)\n",
    "\n",
    "    return multitrack\n",
    "\n",
    "\n",
    "from collections import Counter as C\n",
    "from copy import deepcopy\n",
    "def get_class_weights(source_loader, steps=200, encoder_decoder=True):\n",
    "\n",
    "\n",
    "    default = {k:0 for k in range(PITCHES)}\n",
    "    class_weights = [default for _ in range(INSTRUMENTS)]\n",
    "    for _ in range(steps):\n",
    "        x, _ = next(source_loader)  #(batch_size, time_steps, 5)\n",
    "        \n",
    "        if encoder_decoder:\n",
    "            x = x[0]\n",
    "\n",
    "       \n",
    "        for i in range(INSTRUMENTS):\n",
    "            pcwd = class_weights[i]\n",
    "            ncwd = C(x[:, :, i].ravel().tolist())\n",
    "            for k in pcwd.keys():\n",
    "                pcwd[k] += ncwd[k]\n",
    "\n",
    "            class_weights[i] = pcwd\n",
    "\n",
    "            #class_weights[i][0] += np.sum(1-(x[:, :, i]))\n",
    "            #class_weights[i][1] += np.sum(x[:, :, i])\n",
    "    \n",
    "\n",
    "\n",
    "    for j in range(INSTRUMENTS):\n",
    "        cwd = class_weights[j]\n",
    "        total = sum(cwd.values())\n",
    "        keys = deepcopy(list(cwd.keys()))\n",
    "        for k in keys: \n",
    "            cwd[k] = 1 - (cwd[k])/total\n",
    "\n",
    "        class_weights[j] = cwd\n",
    "    \n",
    "    if INSTRUMENTS == 1:\n",
    "        return class_weights[0]\n",
    "    else:\n",
    "        return class_weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2f54c30d0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2f54c30d0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2f5486710>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2f5486710>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2f54c9f90>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2f54c9f90>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2941fe210>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2941fe210>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, None, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDi  (None, None, 30)             3870      ['input_3[0][0]']             \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, None, 200)            104800    ['time_distributed_5[0][0]']  \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, None, 200)            240800    ['bidirectional_1[0][0]']     \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, None, 200)            240800    ['bidirectional_2[0][0]']     \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, None, 1)]            0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDi  (None, None, 200)            0         ['bidirectional_3[0][0]']     \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDi  (None, None, 30)             3870      ['input_4[0][0]']             \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               [(None, 100),                120400    ['time_distributed_6[0][0]']  \n",
      "                              (None, 100),                                                        \n",
      "                              (None, 100)]                                                        \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               (None, None, 100)            52400     ['time_distributed_7[0][0]',  \n",
      "                                                                     'lstm_6[0][1]',              \n",
      "                                                                     'lstm_6[0][2]']              \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDi  (None, None, 100)            10100     ['lstm_7[0][0]']              \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDi  (None, None, 100)            0         ['time_distributed_8[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " instrument_1 (TimeDistribu  (None, None, 129)            13029     ['time_distributed_9[0][0]']  \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 786199 (3.00 MB)\n",
      "Trainable params: 786199 (3.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def recurrent_encoder_decoder(pitches=PITCHES, instruments=INSTRUMENTS):\n",
    "    Xinp = Input((None, instruments))\n",
    "    Xpromptinp = Input((None, instruments))\n",
    "    note_to_vec = Sequential([Embedding(PITCHES, 30), \n",
    "                              MaxPooling1D(INSTRUMENTS),\n",
    "                              Flatten()\n",
    "    ])\n",
    "\n",
    "    X = TimeDistributed(note_to_vec)(Xinp)\n",
    "    X = Bidirectional(LSTM(100, return_sequences=True))(X)\n",
    "    X = Bidirectional(LSTM(100, return_sequences=True))(X)\n",
    "    X = Bidirectional(LSTM(100, return_sequences=True))(X)\n",
    "    X = TimeDistributed(Dropout(0.2))(X)\n",
    "    _, *internal_state = LSTM(100, return_state=True)(X)\n",
    "\n",
    "    Y = TimeDistributed(note_to_vec)(Xpromptinp)\n",
    "    Y = LSTM(100, return_sequences=True)(Y, initial_state=internal_state)\n",
    "    Y = TimeDistributed(Dense(100, 'relu'))(Y)\n",
    "    Y = TimeDistributed(Dropout(0.3))(Y)\n",
    "    Out = []\n",
    "    for instrument in range(instruments):\n",
    "        Out += [TimeDistributed(Dense(pitches, 'softmax'), name=f'instrument_{instrument+1}')(Y)]\n",
    "    \n",
    "\n",
    "    losses = ['sparse_categorical_crossentropy']*instruments\n",
    "    if instruments == 1:\n",
    "        Out = Out[0]\n",
    "        losses = losses[0]\n",
    "    \n",
    "    In = [Xinp, Xpromptinp]\n",
    "    model = Model(In, Out)\n",
    "    model.compile(Adam(1e-3), loss=losses, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def recurrent(pitches=PITCHES, instruments=INSTRUMENTS):\n",
    "    Xinp = Input((None, instruments))\n",
    "    X = LSTM(200, return_sequences=True)(Xinp)\n",
    "    X = LSTM(100, return_sequences=True)(X)\n",
    "    X = TimeDistributed(Dense(50, 'relu'))(X)\n",
    "    \n",
    "    Out = []\n",
    "    for instrument in range(instruments):\n",
    "        Out += [TimeDistributed(Dense(pitches, 'softmax'), name=f'instrument_{instrument+1}')(X)]\n",
    "    \n",
    "    losses = ['sparse_categorical_crossentropy']*instruments\n",
    "    if instruments == 1:\n",
    "        Out = Out[0]\n",
    "        losses = losses[0]\n",
    "    \n",
    "    In = Xinp \n",
    "    model = Model(In, Out)\n",
    "    model.compile(Adam(1e-3), loss=losses, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model = recurrent_encoder_decoder()\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Training Dataset...: 100%|██████████| 112/112 [00:08<00:00, 13.39it/s]\n",
      "Preparing Validation Dataset...: 100%|██████████| 84/84 [00:03<00:00, 26.10it/s]\n",
      "Preparing Test Dataset...: 100%|██████████| 180/180 [00:02<00:00, 75.50it/s]\n"
     ]
    }
   ],
   "source": [
    "#output_sequence_len = 0 if not encoder_decoder else >=1\n",
    "\n",
    "# Data INFO\n",
    "# ~175K midi files\n",
    "# Files could be short melodies, loop compositions or long symphonies or songs\n",
    "# ~10K midi files in each of the 16 top level subdirectories \n",
    "# Considering 300 midi files at present, at 8 resolution..~ 0.2% Dataset\n",
    "# Generating a polyphonic monophony music (multiple instruments each following a monophonic melody line independently) or type of contrapuntal \n",
    "train_source, val_source, test_source  = process_dataset_in_chunks('./lpd_5/lpd_5_full/0', input_sequence_len=8*100, output_sequence_len=8*400, batch_size=128, topn=600, train_size=0.7, val_size=0.2, resolution=8, prune_rest_note_percent=0.7, encoder_decoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source = ('lpd_5_batched/train_inputs', 'lpd_5_batched/train_outputs')\n",
    "music_loader = load_music_batches(*train_source, encoder_decoder=True)\n",
    "steps = len(os.listdir(train_source[0]))-1\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_source = ('lpd_5_batched/val_inputs', 'lpd_5_batched/val_outputs')\n",
    "val_music_loader = load_music_batches(*val_source, encoder_decoder=True)\n",
    "val_steps = len(os.listdir(val_source[0]))-1\n",
    "val_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "243/243 [==============================] - 6371s 26s/step - loss: 3.5902 - accuracy: 0.1425 - val_loss: 2.9075 - val_accuracy: 0.2145\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 2263s 9s/step - loss: 2.1526 - accuracy: 0.4861 - val_loss: 1.1274 - val_accuracy: 0.7890\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 2327s 10s/step - loss: 1.5081 - accuracy: 0.6953 - val_loss: 0.7699 - val_accuracy: 0.8984\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(music_loader, steps_per_epoch=steps, validation_data=val_music_loader, validation_steps=val_steps, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x41e4d4f50>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x41e4d4f50>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x41f712a10>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x41f712a10>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x420512210>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x420512210>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: encoder-decoder-bilstm-600topn-ep5.5_1instrument/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: encoder-decoder-bilstm-600topn-ep5.5_1instrument/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('encoder-decoder-bilstm-600topn-ep5.5_1instrument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.saving.load_model('encoder-decoder-bilstm-600topn-ep5.5_1instrument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = next(music_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 1, 128), (4901, 1, 128))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_source = ('lpd_5_batched/test_inputs', 'lpd_5_batched/test_outputs')\n",
    "test_input_dir, test_output_dir = test_source\n",
    "test_inputs = os.listdir(test_input_dir)\n",
    "test_outputs = os.listdir(test_output_dir)\n",
    "\n",
    "sample_index = randint(0, len(test_inputs)-1)\n",
    "x = np.load(os.path.join(test_input_dir, test_inputs[sample_index]))\n",
    "y = np.load(os.path.join(test_output_dir, test_outputs[sample_index]))\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [36]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [60]\n",
      " [62]\n",
      " [62]\n",
      " [62]\n",
      " [62]\n",
      " [62]\n",
      " [62]\n",
      " [63]\n",
      " [63]\n",
      " [63]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [46]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [62]\n",
      " [62]\n",
      " [62]\n",
      " [63]\n",
      " [63]\n",
      " [63]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [41]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [44]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [51]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [72]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [55]\n",
      " [75]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [45]\n",
      " [51]\n",
      " [75]\n",
      " [75]\n",
      " [75]\n",
      " [75]\n",
      " [75]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [50]\n",
      " [50]\n",
      " [67]\n",
      " [67]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [43]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [67]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [75]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [53]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [56]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [75]\n",
      " [75]\n",
      " [75]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [67]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [57]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [81]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [58]\n",
      " [74]\n",
      " [74]\n",
      " [74]\n",
      " [74]\n",
      " [74]\n",
      " [70]\n",
      " [70]\n",
      " [70]\n",
      " [70]\n",
      " [70]\n",
      " [70]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [55]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [55]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [48]\n",
      " [55]\n",
      " [55]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [60]\n",
      " [67]\n",
      " [67]\n",
      " [67]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]\n",
      " [58]]\n"
     ]
    }
   ],
   "source": [
    "print(x.argmax(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "composer = compose_music(music_model=model, source_loader=music_loader, topn=5, encoder_decoder=True, print_gen=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing for 200 time steps at 60 bpm\n",
      "Generation :  1\n",
      "[65]\n",
      "Generation :  2\n",
      "[65]\n",
      "Generation :  3\n",
      "[65]\n",
      "Generation :  4\n",
      "[63]\n",
      "Generation :  5\n",
      "[63]\n",
      "Generation :  6\n",
      "[63]\n",
      "Generation :  7\n",
      "[63]\n",
      "Generation :  8\n",
      "[63]\n",
      "Generation :  9\n",
      "[62]\n",
      "Generation :  10\n",
      "[63]\n",
      "Generation :  11\n",
      "[60]\n",
      "Generation :  12\n",
      "[60]\n",
      "Generation :  13\n",
      "[60]\n",
      "Generation :  14\n",
      "[60]\n",
      "Generation :  15\n",
      "[63]\n",
      "Generation :  16\n",
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x333e3b6d0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x333e3b6d0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/backend.py\", line 5158, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/tf_should_use.py\", line 288, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\n",
      "Generation :  17\n",
      "[60]\n",
      "Generation :  18\n",
      "[60]\n",
      "Generation :  19\n",
      "[60]\n",
      "Generation :  20\n",
      "[60]\n",
      "Generation :  21\n",
      "[60]\n",
      "Generation :  22\n",
      "[60]\n",
      "Generation :  23\n",
      "[55]\n",
      "Generation :  24\n",
      "[60]\n",
      "Generation :  25\n",
      "[60]\n",
      "Generation :  26\n",
      "[60]\n",
      "Generation :  27\n",
      "[60]\n",
      "Generation :  28\n",
      "[60]\n",
      "Generation :  29\n",
      "[56]\n",
      "Generation :  30\n",
      "[60]\n",
      "Generation :  31\n",
      "[60]\n",
      "Generation :  32\n",
      "[60]\n",
      "Generation :  33\n",
      "[60]\n",
      "Generation :  34\n",
      "[55]\n",
      "Generation :  35\n",
      "[55]\n",
      "Generation :  36\n",
      "[55]\n",
      "Generation :  37\n",
      "[55]\n",
      "Generation :  38\n",
      "[55]\n",
      "Generation :  39\n",
      "[55]\n",
      "Generation :  40\n",
      "[60]\n",
      "Generation :  41\n",
      "[60]\n",
      "Generation :  42\n",
      "[60]\n",
      "Generation :  43\n",
      "[60]\n",
      "Generation :  44\n",
      "[60]\n",
      "Generation :  45\n",
      "[60]\n",
      "Generation :  46\n",
      "[60]\n",
      "Generation :  47\n",
      "[55]\n",
      "Generation :  48\n",
      "[55]\n",
      "Generation :  49\n",
      "[55]\n",
      "Generation :  50\n",
      "[55]\n",
      "Generation :  51\n",
      "[55]\n",
      "Generation :  52\n",
      "[55]\n",
      "Generation :  53\n",
      "[55]\n",
      "Generation :  54\n",
      "[60]\n",
      "Generation :  55\n",
      "[60]\n",
      "Generation :  56\n",
      "[60]\n",
      "Generation :  57\n",
      "[60]\n",
      "Generation :  58\n",
      "[60]\n",
      "Generation :  59\n",
      "[60]\n",
      "Generation :  60\n",
      "[51]\n",
      "Generation :  61\n",
      "[51]\n",
      "Generation :  62\n",
      "[55]\n",
      "Generation :  63\n",
      "[55]\n",
      "Generation :  64\n",
      "[55]\n",
      "Generation :  65\n",
      "[55]\n",
      "Generation :  66\n",
      "[55]\n",
      "Generation :  67\n",
      "[55]\n",
      "Generation :  68\n",
      "[55]\n",
      "Generation :  69\n",
      "[55]\n",
      "Generation :  70\n",
      "[55]\n",
      "Generation :  71\n",
      "[55]\n",
      "Generation :  72\n",
      "[55]\n",
      "Generation :  73\n",
      "[60]\n",
      "Generation :  74\n",
      "[60]\n",
      "Generation :  75\n",
      "[55]\n",
      "Generation :  76\n",
      "[55]\n",
      "Generation :  77\n",
      "[55]\n",
      "Generation :  78\n",
      "[55]\n",
      "Generation :  79\n",
      "[55]\n",
      "Generation :  80\n",
      "[55]\n",
      "Generation :  81\n",
      "[55]\n",
      "Generation :  82\n",
      "[55]\n",
      "Generation :  83\n",
      "[55]\n",
      "Generation :  84\n",
      "[55]\n",
      "Generation :  85\n",
      "[55]\n",
      "Generation :  86\n",
      "[51]\n",
      "Generation :  87\n",
      "[55]\n",
      "Generation :  88\n",
      "[44]\n",
      "Generation :  89\n",
      "[56]\n",
      "Generation :  90\n",
      "[56]\n",
      "Generation :  91\n",
      "[56]\n",
      "Generation :  92\n",
      "[56]\n",
      "Generation :  93\n",
      "[56]\n",
      "Generation :  94\n",
      "[56]\n",
      "Generation :  95\n",
      "[56]\n",
      "Generation :  96\n",
      "[56]\n",
      "Generation :  97\n",
      "[56]\n",
      "Generation :  98\n",
      "[56]\n",
      "Generation :  99\n",
      "[56]\n",
      "Generation :  100\n",
      "[56]\n",
      "Generation :  101\n",
      "[56]\n",
      "Generation :  102\n",
      "[56]\n",
      "Generation :  103\n",
      "[56]\n",
      "Generation :  104\n",
      "[56]\n",
      "Generation :  105\n",
      "[56]\n",
      "Generation :  106\n",
      "[56]\n",
      "Generation :  107\n",
      "[56]\n",
      "Generation :  108\n",
      "[56]\n",
      "Generation :  109\n",
      "[56]\n",
      "Generation :  110\n",
      "[56]\n",
      "Generation :  111\n",
      "[56]\n",
      "Generation :  112\n",
      "[56]\n",
      "Generation :  113\n",
      "[56]\n",
      "Generation :  114\n",
      "[56]\n",
      "Generation :  115\n",
      "[56]\n",
      "Generation :  116\n",
      "[56]\n",
      "Generation :  117\n",
      "[56]\n",
      "Generation :  118\n",
      "[56]\n",
      "Generation :  119\n",
      "[56]\n",
      "Generation :  120\n",
      "[56]\n",
      "Generation :  121\n",
      "[56]\n",
      "Generation :  122\n",
      "[55]\n",
      "Generation :  123\n",
      "[55]\n",
      "Generation :  124\n",
      "[55]\n",
      "Generation :  125\n",
      "[55]\n",
      "Generation :  126\n",
      "[55]\n",
      "Generation :  127\n",
      "[55]\n",
      "Generation :  128\n",
      "[56]\n",
      "Generation :  129\n",
      "[56]\n",
      "Generation :  130\n",
      "[63]\n",
      "Generation :  131\n",
      "[63]\n",
      "Generation :  132\n",
      "[63]\n",
      "Generation :  133\n",
      "[63]\n",
      "Generation :  134\n",
      "[63]\n",
      "Generation :  135\n",
      "[63]\n",
      "Generation :  136\n",
      "[63]\n",
      "Generation :  137\n",
      "[58]\n",
      "Generation :  138\n",
      "[58]\n",
      "Generation :  139\n",
      "[58]\n",
      "Generation :  140\n",
      "[58]\n",
      "Generation :  141\n",
      "[57]\n",
      "Generation :  142\n",
      "[57]\n",
      "Generation :  143\n",
      "[57]\n",
      "Generation :  144\n",
      "[57]\n",
      "Generation :  145\n",
      "[57]\n",
      "Generation :  146\n",
      "[53]\n",
      "Generation :  147\n",
      "[53]\n",
      "Generation :  148\n",
      "[53]\n",
      "Generation :  149\n",
      "[53]\n",
      "Generation :  150\n",
      "[53]\n",
      "Generation :  151\n",
      "[53]\n",
      "Generation :  152\n",
      "[53]\n",
      "Generation :  153\n",
      "[53]\n",
      "Generation :  154\n",
      "[53]\n",
      "Generation :  155\n",
      "[53]\n",
      "Generation :  156\n",
      "[53]\n",
      "Generation :  157\n",
      "[53]\n",
      "Generation :  158\n",
      "[53]\n",
      "Generation :  159\n",
      "[53]\n",
      "Generation :  160\n",
      "[53]\n",
      "Generation :  161\n",
      "[53]\n",
      "Generation :  162\n",
      "[53]\n",
      "Generation :  163\n",
      "[53]\n",
      "Generation :  164\n",
      "[53]\n",
      "Generation :  165\n",
      "[53]\n",
      "Generation :  166\n",
      "[53]\n",
      "Generation :  167\n",
      "[53]\n",
      "Generation :  168\n",
      "[53]\n",
      "Generation :  169\n",
      "[53]\n",
      "Generation :  170\n",
      "[53]\n",
      "Generation :  171\n",
      "[53]\n",
      "Generation :  172\n",
      "[53]\n",
      "Generation :  173\n",
      "[53]\n",
      "Generation :  174\n",
      "[53]\n",
      "Generation :  175\n",
      "[53]\n",
      "Generation :  176\n",
      "[52]\n",
      "Generation :  177\n",
      "[53]\n",
      "Generation :  178\n",
      "[53]\n",
      "Generation :  179\n",
      "[53]\n",
      "Generation :  180\n",
      "[52]\n",
      "Generation :  181\n",
      "[53]\n",
      "Generation :  182\n",
      "[53]\n",
      "Generation :  183\n",
      "[51]\n",
      "Generation :  184\n",
      "[51]\n",
      "Generation :  185\n",
      "[51]\n",
      "Generation :  186\n",
      "[51]\n",
      "Generation :  187\n",
      "[56]\n",
      "Generation :  188\n",
      "[56]\n",
      "Generation :  189\n",
      "[44]\n",
      "Generation :  190\n",
      "[44]\n",
      "Generation :  191\n",
      "[44]\n",
      "Generation :  192\n",
      "[44]\n",
      "Generation :  193\n",
      "[44]\n",
      "Generation :  194\n",
      "[44]\n",
      "Generation :  195\n",
      "[55]\n",
      "Generation :  196\n",
      "[44]\n",
      "Generation :  197\n",
      "[44]\n",
      "Generation :  198\n",
      "[44]\n",
      "Generation :  199\n",
      "[44]\n",
      "Generation :  200\n",
      "[44]\n",
      "Composition Done...\n",
      "Track Done...\n",
      "Generated Midi file Done...\n",
      "Playing generated_track.mid\n",
      "MIDI file: generated_track.mid\n",
      "Format: 1  Tracks: 2  Divisions: 220\n",
      "Track name: Piano\n",
      "Playing time: ~29 seconds\n",
      "Notes cut: 0\n",
      "Notes lost totally: 0\n",
      "Conversion completed successfully.\n",
      "Generated Audio file Done...\n",
      "Original Track Done...\n",
      "Original Midi file Done...\n",
      "Playing original_track.mid\n",
      "MIDI file: original_track.mid\n",
      "Format: 1  Tracks: 2  Divisions: 220\n",
      "Track name: Piano\n",
      "Playing time: ~29 seconds\n",
      "Notes cut: 0\n",
      "Notes lost totally: 0\n",
      "Conversion completed successfully.\n",
      "Original Audio file Done...\n"
     ]
    }
   ],
   "source": [
    "total_track_length = y.shape[0]\n",
    "composition_length = 200 #int(0.1*total_track_length)\n",
    "TEMPO = 60\n",
    "\n",
    "print(f\"Composing for {composition_length} time steps at {TEMPO} bpm\")\n",
    "for _ in range(composition_length):\n",
    "    composition = next(composer)\n",
    "    print(composition[-1])\n",
    "  \n",
    "\n",
    "\n",
    "output_midi_path = f'generated_track.mid'\n",
    "output_audio_path = f'generated_track.wav'\n",
    "\n",
    "print(\"Composition Done...\")\n",
    "generated_track = make_track(composition, tempo=TEMPO)\n",
    "print(\"Track Done...\")\n",
    "\n",
    "multitrack_to_midi(generated_track, output_midi_path)\n",
    "print(\"Generated Midi file Done...\")\n",
    "midi_to_wav(output_midi_path, output_audio_path)\n",
    "print(\"Generated Audio file Done...\")\n",
    "\n",
    "\n",
    "\n",
    "output_midi_path = 'original_track.mid'\n",
    "output_audio_path = 'original_track.wav'\n",
    "\n",
    "original_track = make_track(composition=y[:composition_length], tempo=TEMPO, from_model=False)\n",
    "print(\"Original Track Done...\")\n",
    "\n",
    "multitrack_to_midi(original_track, output_midi_path)\n",
    "print(\"Original Midi file Done...\")\n",
    "midi_to_wav(output_midi_path, output_audio_path)\n",
    "print(\"Original Audio file Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [74],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [55],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [58],\n",
       "       [62],\n",
       "       [62],\n",
       "       [62],\n",
       "       [62],\n",
       "       [67],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53],\n",
       "       [53]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmax(-1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zk/wsnb2q8d20d9ps6y9yfkkg000000gn/T/ipykernel_1464/1996242684.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  print(y.argmax(-1) == composition)\n"
     ]
    }
   ],
   "source": [
    "print(y.argmax(-1) == composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[55],\n",
       "        [55],\n",
       "        [55],\n",
       "        [55],\n",
       "        [55],\n",
       "        [55],\n",
       "        [48],\n",
       "        [48],\n",
       "        [48],\n",
       "        [48]]),\n",
       " array([[54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54],\n",
       "        [54]]))"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition[1:][:10], y[:277].argmax(-1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 44, 44, 44, 44, 44, 44,\n",
       "        44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "        44, 44, 44, 44, 44, 44, 44, 44, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 46, 46, 46, 46, 46, 46, 46, 46])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 0\n",
    "pred_batch = model.predict([x[ind:ind+1] for x in one_batch[0]])\n",
    "pred_composition = [pred_batch[0].argmax(-1) for inst in range(INSTRUMENTS)]\n",
    "true_composition = [one_batch[1][ind].numpy() for inst in range(INSTRUMENTS)]\n",
    "pred_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 600, 129), TensorShape([128, 600]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_batch.shape, one_batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39,\n",
       "        39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 44, 44, 44, 44, 44, 44, 44,\n",
       "        44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "        44, 44, 44, 44, 44, 44, 44, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,\n",
       "        37, 37, 37, 37, 46, 46, 46, 46, 46, 46, 46, 46, 46])]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689/689 [==============================] - 643s 932ms/step - loss: 7.3065 - instrument_1_loss: 0.8514 - instrument_2_loss: 1.9456 - instrument_3_loss: 1.4665 - instrument_4_loss: 0.9309 - instrument_5_loss: 2.1122 - instrument_1_accuracy: 0.8239 - instrument_2_accuracy: 0.5091 - instrument_3_accuracy: 0.5503 - instrument_4_accuracy: 0.7740 - instrument_5_accuracy: 0.4575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.3065385818481445,\n",
       " 0.8513951301574707,\n",
       " 1.9455796480178833,\n",
       " 1.466457724571228,\n",
       " 0.9308863878250122,\n",
       " 2.112215518951416,\n",
       " 0.8239405155181885,\n",
       " 0.5091147422790527,\n",
       " 0.5502922534942627,\n",
       " 0.7740278244018555,\n",
       " 0.4575483500957489]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_music_loader, steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
